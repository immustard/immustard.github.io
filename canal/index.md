# Canal


<!--more-->



## Canalæ¦‚è¿°



### Canalçš„èµ·æº

é˜¿é‡Œå·´å·´ B2B å…¬å¸, å› ä¸ºä¸šåŠ¡çš„ç‰¹æ€§, å–å®¶ä¸»è¦é›†ä¸­åœ¨å›½å†…, ä¹°å®¶ä¸»è¦é›†ä¸­åœ¨å›½å¤–, æ‰€ä»¥è¡ç”Ÿå‡ºäº†**åŒæ­¥æ­å·å’Œç¾å›½å¼‚åœ°æœºæˆ¿**çš„éœ€æ±‚, ä»2010å¹´å¼€å§‹, é˜¿é‡Œç³»å…¬å¸å¼€å§‹é€æ­¥çš„å°è¯•åŸºäºæ•°æ®åº“çš„æ—¥å¿—è§£æ, è·å–å¢é‡å˜æ›´è¿›è¡ŒåŒæ­¥, ç”±æ­¤è¡ç”Ÿå‡ºäº†å¢é‡ è®¢é˜…&æ¶ˆè´¹ çš„ä¸šåŠ¡. 

Canal æ˜¯ç”¨ Java å¼€å‘çš„åŸºäºæ•°æ®åº“å¢é‡æ—¥å¿—è§£æ, æä¾›å¢é‡æ•°æ® è®¢é˜…&æ¶ˆè´¹ çš„ä¸­é—´ä»¶. ç›®å‰, Canal ä¸»è¦æ”¯æŒäº† MySQL çš„ Binlog è§£æ, è§£æå®Œæˆåæ‰åˆ©ç”¨ Canal Client æ¥å¤„ç†è·å¾—çš„ç›¸å…³æ•°æ®. (æ•°æ®åº“åŒæ­¥éœ€è¦é˜¿é‡Œçš„ Otter ä¸­é—´ä»¶, åŸºäº Canal ). 



### MySQLçš„Binlog

#### ä»€ä¹ˆæ˜¯Binlog

MySQL çš„äºŒè¿›åˆ¶æ—¥å¿—å¯ä»¥è¯´æ˜¯ MySQL æœ€é‡è¦çš„æ—¥å¿—äº†, å®ƒè®°å½•äº†æ‰€æœ‰çš„ DDL å’Œ DML (é™¤äº†æ•°æ®æŸ¥è¯¢è¯­å¥) è¯­å¥, ä»¥äº‹ä»¶è¡Œé©¶è®°å½•, è¿˜åŒ…æ‹¬è¯­å¥æ‰€æ‰§è¡Œçš„æ¶ˆè€—çš„æ—¶é—´. 

**Binlogæ˜¯äº‹åŠ¡å®‰å…¨æ€§çš„**. 

> ä¸€èˆ¬æ¥è¯´, SQLè¯­è¨€åˆ†ä¸ºä¸‰ç±»: 
>
> * `DML`(Data Manipulation Language): æ•°æ®æ“çºµè¯­è¨€, æœ€å¸¸ç”¨çš„å¢åˆ æ”¹æŸ¥å°±æ˜¯è¿™ç±», æ“ä½œå¯¹è±¡æ˜¯æ•°æ®è¡¨ä¸­çš„è®°å½•
> * `DDL`(Data Definition Language): æ•°æ®å®šä¹‰è¯­è¨€, ä¾‹å¦‚å»ºåº“ã€å»ºè¡¨ç­‰
> * `DCL`(Data Control Language): æ•°æ®æ§åˆ¶è¯­è¨€, å¦‚ Grantã€Rollback ç­‰, å¸¸è§äºæ•°æ®åº“å®‰å…¨ç®¡ç†



Binlogä¸¤ä¸ªæœ€é‡è¦çš„ä½¿ç”¨åœºæ™¯:

1. MySQL Replication åœ¨ Master ç«¯å¼€å¯ Binlog, Master æŠŠå®ƒçš„ Binlog ä¼ é€’ç»™ Slaves æ¥è¾¾åˆ° Master-Slave æ•°æ®ä¸€è‡´çš„ç›®çš„
2. æ•°æ®æ¢å¤, é€šè¿‡ä½¿ç”¨ MySQL Binlog å·¥å…·æ¥ä½¿æ¢å¤æ•°æ®



#### Binlogåˆ†ç±»

MySQL Binlog çš„æ ¼å¼æœ‰ä¸‰ç§, åˆ†åˆ«æ˜¯ STATEMENT,MIXED,ROW . åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ä»¥é€‰é…: `binlog_format=statement|mixed|row`

* `statement`: è¯­å¥çº§, binlog ä¼šè®°å½•æ¯æ¬¡æ‰§è¡Œå†™æ“ä½œçš„è¯­å¥. ç›¸å¯¹`row`æ¨¡å¼èŠ‚çœç©ºé—´, ä½†æ˜¯å¯èƒ½äº§ç”Ÿä¸ä¸€è‡´æ€§. ğŸŒ°: `update table set create_date=now()`, å¦‚æœç”¨è¿™ç§æ¨¡å¼è¿›è¡Œæ¢å¤, ç”±äºæ‰§è¡Œæ—¶é—´çš„ä¸åŒäº§ç”Ÿçš„æ•°æ®å°±å¯èƒ½ä¸åŒ. 
  * ä¼˜åŠ¿: èŠ‚çœç©ºé—´
  * åŠ£åŠ¿: å¯èƒ½é€ æˆæ•°æ®ä¸ä¸€è‡´
* `row`: è¡Œçº§, binlog ä¼šè®°å½•æ¯æ¬¡æ“ä½œåæ¯è¡Œè®°å½•çš„å˜åŒ–.
  * ä¼˜åŠ¿: ä¿æŒæ•°æ®çš„ç»å¯¹ä¸€è‡´æ€§
  * åŠ£åŠ¿: å ç”¨ç©ºé—´å¤§
* `mixed`: statementçš„å‡çº§ç‰ˆ, ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†å› ä¸ºä¸€äº›æƒ…å†µè€Œé€ æˆçš„ statementæ¨¡å¼ ä¸ä¸€è‡´çš„é—®é¢˜. mixedé»˜è®¤è¿˜æ˜¯statement, åœ¨æŸäº›æƒ…å†µä¸‹(ğŸŒ°): å½“å‡½æ•°ä¸­åŒ…å«`UUID()`æ—¶; åŒ…å«`AUTO_INCREMENT`å­—æ®µçš„è¡¨è¢«æ›´æ–°ç­‰. è¿™äº›æƒ…å†µä¸‹ä¼šæŒ‰ç…§rowçš„æ–¹å¼å¤„ç†.
  * ä¼˜åŠ¿: èŠ‚çœç©ºé—´, åŒäº‹å…¼é¡¾äº†ä¸€å®šçš„ä¸€è‡´æ€§
  * åŠ£åŠ¿: è¿˜æœ‰ä¸€äº›æä¸ªåˆ«æƒ…å†µä¾æ—§ä¼šé€ æˆä¸ä¸€è‡´, å¦å¤– statement å’Œ mixed å¯¹äºéœ€è¦å¯¹ binlog çš„ç›‘æ§æƒ…å†µéƒ½ä¸æ–¹ä¾¿

**ç»¼ä¸Š, Canlæƒ³åšç›‘æ§åˆ†æ, é€‰æ‹© row æ ¼å¼æ¯”è¾ƒåˆé€‚**



### Canalçš„å·¥ä½œåŸç†

#### MySQLä¸»ä»å¤åˆ¶è¿‡ç¨‹

1. Master ä¸»åº“å°†æ”¹å˜è®°å½•, å†™åˆ° binlog ä¸­;
2. Slave ä»åº“å‘ MySQL Slave å‘é€ dump åè®®, å°† Master ä¸»åº“çš„ binlog events æ‹·è´åˆ°å®ƒçš„ä¸­ç»§æ—¥å¿—(relay log);
3. Slave ä»åº“è¯»å–å¹¶é‡åšä¸­ç»§æ—¥å¿—ä¸­çš„äº‹ä»¶, å°†æ”¹å˜çš„æ•°æ®åŒæ­¥åˆ°è‡ªå·±çš„æ•°æ®åº“. 

<center>     <img style="border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"      src="https://cdn.jsdelivr.net/gh/immustard/gallery/pictures/202207260907350.png" width = "65%" alt="" onclick="window.open(this.src)"/>     <br>     <div style="color:orange; border-bottom: 1px solid #d9d9d9;     display: inline-block;     color: #999;     padding: 2px;">       MySQLä¸»ä»å¤åˆ¶è¿‡ç¨‹   	</div> </center>

#### Canalçš„å·¥ä½œåŸç†

ç†è§£äº†ä¸Šé¢çš„è¿‡ç¨‹, Canalçš„åŸç†å°±å¾ˆç®€å•, å°±æ˜¯æŠŠè‡ªå·±*ä¼ªè£…æˆSlave*, å‡è£…ä» Master å¤åˆ¶æ•°æ®



## MySQLçš„å‡†å¤‡

MySQLçš„å®‰è£…è¿™é‡Œå°±ä¸è¯´äº†, ç½‘ä¸Šæœ‰å¾ˆå¤š. 

1. é¦–å…ˆ, å»ºæ•°æ®åº“: `canal_test`

2. ç„¶åå»ºè¡¨: 

   ```sql
   create table user_info {
       `id` int,
       `name` varchar(255),
       `gender` varchar(255)
   }
   ```

3. ä¿®æ”¹é…ç½®æ–‡ä»¶å¼€å¯binlog

   ```shell
   [root@hadoop102 ~]# vi /etc/my.cnf
   
   # æ‰“å¼€binlog
   log-bin=mysql-bin
   # é€‰æ‹©ROWæ¨¡å¼
   binlog-format=row
   # é…ç½®MYSQL replactionéœ€è¦å®šä¹‰, ä¸è¦å’Œcanalçš„slaveIdé‡å¤
   server_id=1
   binlog-do-db=canal_test
   ```

   `binlog-do-db`æ ¹æ®å®é™…æƒ…å†µé…ç½®, å¦‚æœä¸é…ç½®, åˆ™è¡¨ç¤ºæ‰€æœ‰æ•°æ®åº“å‡å¼€å¯ binlog.
   
4. é‡å¯ MySQL

   ```shell
   sudo systemctl restart mysqld
   ```

   

## Canalçš„ä¸‹è½½å’Œå®‰è£…

### ä¸‹è½½

ä¸‹è½½åœ°å€: https://github.com/alibaba/canal/releases

1. ä¸‹è½½å¯¹åº”ç‰ˆæœ¬: `canal.deployer-xxx.tar.gz`

2. è§£å‹åˆ°å¯¹åº”ä½ç½®



### ä¿®æ”¹ canal.properties

```shell
[root@hadoop102 conf]# pwd
/opt/module/canal/conf
[root@hadoop102 conf]# vi canal.properties 
```

è¿™ä¸ªæ–‡ä»¶æ˜¯ canal çš„åŸºæœ¬é€šç”¨é…ç½®, canalç«¯å£å·é»˜è®¤æ˜¯`11111`. 

å¤šå®ä¾‹é…ç½®: ä¸€ä¸ª canal æœåŠ¡ä¸­å¯ä»¥æœ‰å¤šä¸ªinstance, conf/ ä¸‹æ¯ä¸€ä¸ª example å³æ˜¯ä¸€ä¸ªå®ä¾‹, æ¯ä¸ªå®ä¾‹ä¸‹é¢éƒ½æœ‰ç‹¬ç«‹çš„é…ç½®æ–‡ä»¶. éœ€ä¿®æ”¹`canal.destinations=å®ä¾‹1,å®ä¾‹2,å®ä¾‹3`



### ä¿®æ”¹ instance.properties

```shell
[root@hadoop102 example]# pwd
/opt/module/canal/conf/example
[root@hadoop102 example]# vi instance.properties
```

```properties
## mysql serverId , v1.0.26+ will autoGen
## v1.0.26ç‰ˆæœ¬åä¼šè‡ªåŠ¨ç”ŸæˆslaveIdï¼Œæ‰€ä»¥å¯ä»¥ä¸ç”¨é…ç½®
# canal.instance.mysql.slaveId=0

# æ•°æ®åº“åœ°å€
canal.instance.master.address=127.0.0.1:3306
# binlogæ—¥å¿—åç§°
canal.instance.master.journal.name=mysql-bin.000001
# mysqlä¸»åº“é“¾æ¥æ—¶èµ·å§‹çš„binlogåç§»é‡
canal.instance.master.position=154
# mysqlä¸»åº“é“¾æ¥æ—¶èµ·å§‹çš„binlogçš„æ—¶é—´æˆ³
canal.instance.master.timestamp=
canal.instance.master.gtid=

# username/password
# åœ¨MySQLæœåŠ¡å™¨æˆæƒçš„è´¦å·å¯†ç 
canal.instance.dbUsername=canal
canal.instance.dbPassword=canal
# å­—ç¬¦é›†
canal.instance.connectionCharset = UTF-8
# enable druid Decrypt database password
canal.instance.enableDruid=false

# table regex .*\\..*è¡¨ç¤ºç›‘å¬æ‰€æœ‰è¡¨ ä¹Ÿå¯ä»¥å†™å…·ä½“çš„è¡¨åï¼Œç”¨ï¼Œéš”å¼€
canal.instance.filter.regex=.*\\..*
# mysql æ•°æ®è§£æè¡¨çš„é»‘åå•ï¼Œå¤šä¸ªè¡¨ç”¨ï¼Œéš”å¼€
canal.instance.filter.black.regex=
```



## å®æ—¶ç›‘æ§æµ‹è¯•

### TCPæ¨¡å¼æµ‹è¯•

1. åˆ›å»ºä¸€ä¸ª maven é¡¹ç›®, åœ¨`pom.xml`ä¸­é…ç½®:

	```xml
	<dependency>
    <groupId>com.alibaba.otter</groupId>
    <artifactId>canal.client</artifactId>
    <version>1.1.2</version>
	</dependency>
	```

2. åˆ›å»ºç±»: `CanalClient`

   ```java
   package org.mustard.app;
   
   import com.alibaba.fastjson.JSONObject;
   import com.alibaba.otter.canal.client.CanalConnector;
   import com.alibaba.otter.canal.client.CanalConnectors;
   import com.alibaba.otter.canal.protocol.CanalEntry;
   import com.alibaba.otter.canal.protocol.Message;
   import com.google.protobuf.ByteString;
   import com.google.protobuf.InvalidProtocolBufferException;
   
   import java.net.InetSocketAddress;
   import java.util.List;
   
   public class CanalClient {
   
       public static void main(String[] args) throws InvalidProtocolBufferException {
           // è·å–è¿æ¥å¯¹è±¡
           CanalConnector canalConnector = CanalConnectors.newSingleConnector(new InetSocketAddress("hadoop102", 11111), "example", "", "");
   
           // è·å–è¿æ¥
           canalConnector.connect();
   
           // æŒ‡å®šè¦ç›‘æ§çš„æ•°æ®åº“
           canalConnector.subscribe("canal.*");
   
           long idx = 0;
           while (true) {
               // è·å–message
               Message msg = canalConnector.get(100);
   
               List<CanalEntry.Entry> entries = msg.getEntries();
               if (entries.size() <= 0) {
                   System.out.println((++idx) + ". æ²¡æœ‰æ•°æ®, ç­‰ä¸€ä¼šå„¿");
                   try {
                       Thread.sleep(1000);
                   } catch (InterruptedException e) {
                       e.printStackTrace();
                   }
               } else {
                   for (CanalEntry.Entry entry : entries) {
                       // è·å–è¡¨å
                       String tableName = entry.getHeader().getTableName();
   
                       // Entryç±»å‹
                       CanalEntry.EntryType entryType = entry.getEntryType();
   
                       if (CanalEntry.EntryType.ROWDATA.equals(entryType)) {
                           // åºåˆ—åŒ–æ•°æ®
                           ByteString storeValue = entry.getStoreValue();
   
                           // ååºåˆ—åŒ–
                           CanalEntry.RowChange rowChange = CanalEntry.RowChange.parseFrom(storeValue);
                           // è·å–äº‹ä»¶ç±»å‹
                           CanalEntry.EventType eventType = rowChange.getEventType();
   
                           // è·å–å…·ä½“æ•°æ®
                           List<CanalEntry.RowData> rowDatasList = rowChange.getRowDatasList();
                           // éå†æ‰“å°
                           for (CanalEntry.RowData rowData : rowDatasList) {
                               List<CanalEntry.Column> beforeColumnsList = rowData.getBeforeColumnsList();
                               JSONObject beforeData = new JSONObject();
                               for (CanalEntry.Column column : beforeColumnsList) {
                                   beforeData.put(column.getName(), column.getValue());
                               }
   
                               List<CanalEntry.Column> afterColumnsList = rowData.getAfterColumnsList();
                               JSONObject afterData = new JSONObject();
                               for (CanalEntry.Column column : afterColumnsList) {
                                   afterData.put(column.getName(), column.getValue());
                               }
   
                               System.out.println("TableName: " + tableName +
                                       ", EventType: " + eventType +
                                       ", Before: " + beforeData +
                                       ", After: " + afterData);
                           }
                       }
                   }
               }
           }
       }
   
   }
   ```

   

### Kafkaæ¨¡å¼æµ‹è¯•

1. ä¿®æ”¹ canal.properties ä¸­ canal çš„è¾“å‡º model

   ```properties
   ######### common argument #############
   canal.id = 1
   canal.ip =
   canal.port = 11111
   canal.metrics.pull.po rt = 11112
   canal.zkServers =
   # flush data to zk
   canal.zookeeper.flush.period = 1000
   canal.withoutNetty = false
   # tcp, kafka, RocketMQ
   canal.serverMode = kafka
   # flush meta cursor/parse position to file
   ```

2. ä¿®æ”¹ kafka é›†ç¾¤çš„åœ°å€

   ```properties
   ######### Kafka #############
   kafka.bootstrap.servers = hadoop102:9092
   ```

3. ä¿®æ”¹ instance.properties è¾“å‡ºåˆ° Kafka çš„ä¸»é¢˜ä»¥åŠåˆ†åŒºæ•°

   ```properties
   # mq config
   canal.mq.topic=canal_test
   ```

   é»˜è®¤è¿˜æ˜¯è¾“å‡ºåˆ°æŒ‡å®š Kafka ä¸»é¢˜çš„ä¸€ä¸ªåˆ†åŒº, å› ä¸ºå¤šä¸ªåˆ†åŒºå¹¶è¡Œå¯èƒ½ä¼šæ‰“ä¹± binlog çš„é¡ºåº, å¦‚æœè¦æé«˜å¹¶è¡Œåº¦, é¦–å…ˆè®¾ç½® kafka çš„åˆ†åŒºæ•° > 1, ç„¶åè®¾ç½®`canal.mq.partitionHash`å±æ€§. 

4. å¯åŠ¨ canal

5. ç„¶åæµ‹è¯•: 

   ```shell
   [root@hadoop102 kafka_2.12-2.8.1]# ./bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic canal_test
   {"data":[{"id":"5","name":"aria","gender":"female"}],"database":"canal_test","es":1658589672000,"id":2,"isDdl":false,"mysqlType":{"id":"int(11)","name":"varchar(255)","gender":"varchar(255)"},"old":null,"pkNames":null,"sql":"","sqlType":{"id":4,"name":12,"gender":12},"table":"user_info","ts":1658589672852,"type":"DELETE"}
   {"data":[{"id":"5","name":"aria","gender":"female"}],"database":"canal_test","es":1658589697000,"id":3,"isDdl":false,"mysqlType":{"id":"int(11)","name":"varchar(255)","gender":"varchar(255)"},"old":null,"pkNames":null,"sql":"","sqlType":{"id":4,"name":12,"gender":12},"table":"user_info","ts":1658589697570,"type":"INSERT"}
   ```

   


