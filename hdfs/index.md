# Hadoop分布式文件系统——HDFS


<!--more-->

## 介绍

**HDFS (Hadoop Distributed File System)** 是 Hadoop下的分布式文件系统, 具有高容错、高吞吐量等特性, 可以部署在低成本的硬件上. 



## 设计原理

### 架构

HDFS 遵从主/从架构, 由**单个** NameNode(NN) 和 **多个** DataNote(DN) 组成:

* **NameNode**: 负责执行有关`文件系统命名空间`的操作, 🌰: 打开, 关闭、重命名文件和目录等. 同事还负责集群元数据的存储, 记录着文件中各个数据块的位置信息. 

  > 也就是说主要是用来存储元数据的. 

* **DataNode**: 负责提供来自文件系统客户端的读写请求, 执行块的创建, 删除等操作. 

  > 用来存储具体文件的. 



### 文件系统命名空间

HDFS 的`文件系统命名空间`的层次结构与大多数文件系统类似(🌰: Linux), 支持目录和文件的创建、移动、删除和重命名等操作, 支持配置用户和访问权限, **但不支持硬链接和软连接**. `NameNode`负责维护文件系统名称空间, 记录对名称空间或其属性的任何更改. 

 

### 数据复制

由于 Hadoop 是被设计运行在廉价的机器上的, 这就一位置硬件其实是不可靠的. 所以为了保证高容错, HDFS 提供了**数据复制**机制. HDFS 将每个文件存储为一系列**块**, 每个块由多个副本来保证容错, 块的大小和复制因子可配置 (默认下, 块为128M, 复制因子为3). 



#### 数据复制的实现原理

大型的 HDFS 实例通常分布在多个机架的多台服务器上, 不同机架上的两台服务器之间通过交换机进行通讯. 大多数情况下, 同一机架中的服务期间的网络带宽大于不同机架中的服务器之间的带宽. 所以, HDFS 采用**机架感知副本放置策略**. 



🌰, 对于默认情况, 当复制因子为3时, HDFS 的放置策略是:

在写入程序位于 `DN` 上时, 就优先将写入文件的一个副本放置在该 `DN` 上, 否则放在**随机** `DN` 上. 之后另一个远程机架上的任意一个节点上放置另一个副本, 并在该机加上的另一个节点放置最后一个副本. 这么做的好处就是可以减少机架间的写入流量, 从而提高写入性能. 



如果复制因子大于3, 则随机确定第4个和之后副本的放置位置, 同时需要保持每个机架的副本数量低于上限, 上限值通常为 `(复制系数 - 1)/机架数 + 2`. 

**注意**: 不允许同一个 `DN` 上具有同一块的相同副本. 每个机架最多存储两份备份. 但是在这两个条件无法被满足的一些情况下, 这些条件会被忽略. 并且 HDFS 允许自定义布局算法. 



#### 副本的选择

副本的选择为了最大限度地减少带宽消耗和读取延迟, HDFS 在执行读取请求时, 优先读取距离读取其最近的副本(物理层面上). 也就是说, 如果与读取器节点相同的机架上存在副本, 则优先选择该副本. 如果 HDFS 集群跨越多个数据中心, 优先选择本地数据中心上的副本. 



### 架构的稳定性

#### 心跳机制和重新复制

每个 `DN` 定期向 `NN` 发送心跳, 如果超过指定时间没有收到心跳, 会将该 `DN` 标记为已死亡. `NN` 不会将任何新的 IO请求 转发给标记为死亡的 `DN`, 也不会再使用已死亡的 `DN` 上的数据. 



`DN` 也会将其所有数据块列表定时发送给 `NN`, 并且在发送之前 `DN` 会检测校验和是否正常, 若不正常, 则不会发送给 `NN`. 所以 `NN` 会检测出那些数据块已经损坏. 



由于数据不再可用, 可能会导致某些块副本数小于复制因子, 所以 `NN` 会跟踪这些块, 并在必要的时候进行重新复制. 



#### 数据的完整性

由于存储设备故障等原因, 存储在 `DN` 上的数据块也会发生损坏. 为了避免读取到一损坏的数据而导致错误, HDFS 提供了数据完整性机制来保存数据的完整性:

当客户端创建 HDFS 文件时,  它会计算文件的每个块的`校验和`, 并将`校验和`存储在同一 HDFS 命名空间下的单独的隐藏文件中. 当客户端检索文件内容时, 它会校验从每个 `DN` 接收的数据是否与存储在关联校验和文件中的`校验和`匹配. 如果不匹配, 代表数据已经损坏, 这个时候客户端会选择其他 `DN` 获取副本, 并重新校验. 



#### 元数据的磁盘故障

`FsImage` 和 `EditLog` 是 HDFS 的核心数据, 这些数据的以为丢失可能导致整个 HDFS 服务不可用. 为了避免, 可以配置 `NN` 使其支持 `FsImage` 和 `EditLog` 多副本同步, 这样 `FsImage` 或 `EditLog` 的任何改变都会引起每个副本的同步更新. 



#### 支持快照

快照支持在特定时刻存储数据副本, 在数据意外损坏时, 可以通过回滚操作恢复到简况的数据状态. 



## 特点

1. 高容错

   上面已经介绍了 HDFS 采用数据的多副本方案, 所以部分硬件的损坏并不会导致全部数据的丢失. 

2. 高吞吐量

   HDFS 设计的重点是支持高吞吐量的数据访问, 而不是低延迟的数据访问. 

3. 大文件支持

   文件大小应是 GB 到 TB 级别的. 

4. 简单一致性模型

   HDFS 更适合一次写入多次读取 (write-once-read-many) 的访问模型. **支持将内容追加到文件末尾, 但不支持数据的随机访问, 不能从文件任意位置新增数据**.

5. 跨平台移植性

   HDFS 具有良好的跨平台移植性, 使得其他大数据计算框架都将其作为数据持久化存储的首选方案. 

---

> 作者:   
> URL: https://buli-home.cn/hdfs/  

