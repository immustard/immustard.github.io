[{"categories":["Java"],"content":" 今天进行了一场面试, 面试官在问我关于HashMap的时候, 感觉自己回答的不是很好, 所以现在索性就梳理一下Java关于集合的这部分知识. 主要是问了这么几个问题: HashMap是线程安全的么 那线程安全的map是哪种? 在定义HashMap的时候会有定义长度的习惯么? HashMap的底层是怎么实现的? HashMap是如何存储的? HashMap最大长度是多少? 或者说是达到多大的长度就需要扩容了? (这个没答上来…😭) 说到Java的Collection就一定会放出这张神图 根据这张图能发现, 这一切的一切都起始于Iterable接口. ","date":"2022-02-24","objectID":"/java_collection/:0:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"Iterable 从源码里能看到, 这个接口允许对象成为for-each的循环目标, 也就是增强型for循环, 是Java中的一种语法糖. List\u003cObject\u003e list = new ArrayList(); // 补充: 数组也可`for-each`遍历 // Object[] list = new Object[5]; for (Object obj: list) {} 其他遍历方式 JDK 1.8 之前, Iterable只有一个方法: Iterator\u003cT\u003e iterator(); 这个接口能够创建一个轻量级的迭代器, 用于安全的遍历元素, 移除元素, 添加元素. 其中涉及了一个概念就是fail-fast. 总结起来就是: 能创建迭代器进行元素添加和删除的话, 就尽量使用迭代器进行添加和删除操作. for (Iterator it = list.iterator(); it.hasNext(); ) { System.out.println(it.next()); } ","date":"2022-02-24","objectID":"/java_collection/:1:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"顶层接口 Collection是一个顶层接口, 主要是用来定义集合的约定. List接口也是一个顶层接口, 继承了Collection接口, 同时也是ArrayList, LinkedList等集合元素的父类. Set接口位于与List接口同级的层次上, 它同事也继承了Collection接口. Set接口提供了额外的规定. 对add(), equals(), hashCode()方法提供了额外的标准. Queue是和List, Set接口并列的Collection的三大接口之一. Queue的设计用来在处理之前保持元素的访问次序. 除了Collection基础的操作外, 对立提供了额外的插入, 读取, 检查操作. SortSet接口直接继承与Set接口, 使用Comparable对元素进行自然排序或者使用Comparator在创建时对元素提供定制的排序规则. set的迭代器将按升序元素顺序遍历集合. Map是一个支持key-value存储的对象, Map不能包含重复的key, 每个键最多映射一个值. 这个接口替代了Dictionary类, Dictionary是一个抽象类而不是接口. ","date":"2022-02-24","objectID":"/java_collection/:2:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"ArrayList ArrayList是实现List接口的可扩容数组(动态数组), 它的内部是基于数组实现的, 具体的定义: public class ArrayList\u003cE\u003e extends AbstractList\u003cE\u003e implements List\u003cE\u003e, RandomAccess, Cloneable, java.io.Serializable {...} ArrayList可以实现所有可选择的列表操作, 允许所有元素 (包括 null). ArrayList还提供了内部存储list的方法, 它能够完全替代Vector, 只有一点例外, ArrayList不是线程安全的容器. 下面会说到Vector ArrayList有一个容量的概念, 这个数组的容量就是List用来存储元素的容量. 在不声明容量的时候, 默认的是10. 当达到当前容量上限的时候, 就会进行扩容, 负载因子为0.5, 即: 旧容量 * 1.5 ==\u003e 10-\u003e15-\u003e22-\u003e33... ArrayList的上限为Integer.MAX_VALUE - 8(232 - 8). ArrayList不是线程安全的容器, 所以可以使用线程安全的List: List list = Collections.synchronizedList(new ArrayList\u003c\u003e()); ArrayList具有fail-fast快速失败机制, 当在迭代集合的过程中, 该集合发成了改变的时候, 就可能会发生fail-fast, 抛出ConcurrentModificationException异常. ","date":"2022-02-24","objectID":"/java_collection/:3:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"Vector Java中的Vector类是允许不同类型共存的变长数组, Java.util.Vector提供了向量(Vector)类以实现类似动态数组的功能. 在相对于ArrayList来说, Vector线程是安全的, 也就是说是同步的. 因为Vector对内部的每个方法都是简单粗暴的上锁, 所以访问元素的效率远远低于ArrayList. 还有一点在扩容上, ArrayList扩容后的数组长度会增加50%, 而Vector的扩容长度后数组是翻倍. ","date":"2022-02-24","objectID":"/java_collection/:4:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"LinkedList LinkedList是一个双向链表, 允许所有元素 (包括 null): LinkedList所有的操作都可以表现为双向性, 索引到链表的操作将遍历从头到尾, 看那个距离短为遍历顺序. LinkedList不是线程安全的容器, 所以可以使用线程安全的Set: List list = Collections.synchronizedList(new LinkedList\u003c\u003e()); 因为LinkedList是一个双向链表, 所以没有初始化大小, 没有扩容机制. ","date":"2022-02-24","objectID":"/java_collection/:5:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"Stack 堆栈(Stack)就是常说的后入先出的容器. 它继承了Vector类, 提供了常用的pop, push和peek操作, 以及判断stack是否为空的empty方法和寻找与栈顶距离的search方法. ","date":"2022-02-24","objectID":"/java_collection/:6:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"HashSet HashSet是Set接口的实现类, 有哈希表支持 (实际上HashSet是HashMap的一个实例), 不能保证集合的迭代顺序. 允许所有元素 (包括 null). HashSet不是线程安全的容器, 所以可以使用线程安全的Set: Set set = Collections.synchronizedSet(new HashSet\u003c\u003e()); 支持fail-fast机制. 因为HashSet的底层实际使用HashMap实现的, 所以和HashMap的容量和扩容机制是一致的: 在不声明容量的时候, 默认的是16. 当达到当前容量上限的时候, 就会进行扩容, 负载因子为0.75, 即: 旧容量 * 1.75 ==\u003e 16-\u003e28-\u003e49-\u003e85... ","date":"2022-02-24","objectID":"/java_collection/:7:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"TreeSet TreeSet是一个基于TreeMap的NavigableSet实现. 这些元素使用他们的自然排序或者在创建时提供的Comparator进行排序, 具体取决于使用的构造函数. 此实现为基本操作add, remove, contains提供了log(n)的时间成本. HashSet不是线程安全的容器. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:8:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"LinkedHashSet LinkedHashSet继承体系 LinkedHashSet是Set接口的Hash表和LinkedList的实现. 但是这个实现不同于HashSet的是, 它维护者一个贯穿所有条目的双向列表. 此链表定义了元素插入集合的顺序. 注意: 如果元素重新插入, 则插入顺序不会受到影响. LinkedHashSet有两个影响其构成的参数: 初始容量和负载因子. 它们的定义与HashSet完全相同. 但是对于LinkedHashSet, 选择过高的初始容量值的开销要比HashSet小, 因为LinkedHashSet的迭代次数不收容量影响. LinkedHashSet不是线程安全的容器. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:9:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"PriorityQueue PriorityQueue(优先级队列)是AbstractQueue的实现类, 其中的元素根据自然排序(最小元素最先出)或者通过构造函数时期提供的Comparator来排序, 具体根据构造器判断. 注意: PriorityQueue不允许null元素. 队列的头在某种意义上是指定顺序的最后一个元素. 队列查找操作poll, remove, peek和element访问队列头部元素. PriorityQueue是无界队列(无限制的), 但是有内部capacity, 用户控制用于在队列中存储元素的数组大小. 该类以及迭代器实现了Collection, Iterator接口的所有可选方法. 这个迭代器提供了iterator()方法不能保证以任何特定顺序遍历PriorityQueue. 如果需要有序遍历的话, 可以考虑使用Arrays.sort(pq.toArray()). PriorityQueue必须存储的可比较的对象, 如果不是的话, 则必须指定比较器. PriorityQueue不是线程安全的容器, 而线程安全的类是PriorityBlockingQueue. ","date":"2022-02-24","objectID":"/java_collection/:10:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"HashMap HashMap是一个利用哈希表原理来存储元素的集合, 允许空的key-value键值对. HashMap的默认初始用量和负载因子和HashSet一致. HashMap不是线程安全的容器. ","date":"2022-02-24","objectID":"/java_collection/:11:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"TreeMap 一个基于NavigableMap实现的红黑树. 这个map根据key自认排序存储, 或者通过Comparator进行定制排序. TreeMap为containsKey,get,put和remove方法提供了log(n)的时间开销. TreeMap不是线程安全的容器. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:12:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"LinkedHashMap LinkedHashMap是Map接口的哈希表和链表的实现. 这个实现与HashMap的不同之处在于它维护了一个贯穿其所有条目的双向链表. 这个链表中定义的顺序, 通常是插入的顺序. 提供了一个特殊的构造器: LinkedHashMap(int,float,boolean), 其遍历的顺序是其最后一次访问的顺序. 可以重写removeEldestEntry(Map.Entry)方法, 以便在将新映射添加到map时强制删除过期映射的策略. 这个类提供了所有可选择的map操作, 并且允许null元素. 由于维护链表的额外开销, 性能可能会低于HashMap, 有一条除外: 遍历LinkedHashMap中的collection-views需要与map.size成正比, 无论其容量如何. HashMap的迭代看起来开销更大, 因为还要求时间与其容量成正比. LinkedHashMap有两个因素影响了它的构成: 初始容量和负载因子. LinkedHashMap不是线程安全的容器. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:13:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"HashTable 与HashMap不同的是, HashTable是线程安全的. 任何非空对象都可以用作键或值. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:14:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"IdentityHashMap IdentityHashMap 是一个比较小众的Map实现类. IdentityHashMap不是一个通用的Map实现, 虽然这个类实现了Map接口, 但是它故意违反了Map的约定, 该约定要求在比较对象时使用equals方法, 此类仅适用于需要引用相等语义的极少数情况. IdentityHashMap不是线程安全的容器. 支持fail-fast机制. ","date":"2022-02-24","objectID":"/java_collection/:15:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"WeakHashMap WeakHashMap类基于哈希表的Map基础实现, 带有弱键. WeakHashMap中的entry当不再使用时还会自动移除. 也就是说, WeakHashMap中的entry不会增加其引用计数. 基于map接口, 是一种弱键相连, WeakHashMap里面的键会自动回收. 支持null键和null值. 支持fail-fast机制 WeakHashMap经常用作缓存. ","date":"2022-02-24","objectID":"/java_collection/:16:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Java"],"content":"集合实现类特征图 下面这个表格汇总了部分集合框架的主要实现类的特征 集合 排序 随机访问 key-value存储 重复元素 空元素 线程安全 ArrayList ✅ ✅ ❌ ✅ ✅ ❌ LinkedList ✅ ❌ ❌ ✅ ✅ ❌ HashSet ❌ ❌ ❌ ❌ ✅ ❌ TreeSet ✅ ❌ ❌ ❌ ❌ ❌ HashMap ❌ ✅ ✅ ❌ ✅ ❌ TreeMap ✅ ✅ ✅ ❌ ❌ ❌ Vector ✅ ✅ ❌ ✅ ✅ ✅ HashTable ❌ ✅ ✅ ❌ ❌ ✅ ConcurrentHashMap ❌ ✅ ✅ ❌ ❌ ✅ Stack ✅ ❌ ❌ ✅ ✅ ✅ CopyOnWriteArrayList ✅ ✅ ❌ ✅ ✅ ✅ ","date":"2022-02-24","objectID":"/java_collection/:17:0","tags":["Java"],"title":"Java集合","uri":"/java_collection/"},{"categories":["Security"],"content":"什么是SQL注入 SQL注入攻击是通过将恶意的SQL语句插入到应用的输入参数中, 再在后台SQL服务器上解析执行的攻击. 是目前对数据库进行攻击的最常用手段之一. 主要原因是程序对用户输入数据的合法性没有判断和处理. ","date":"2022-02-24","objectID":"/sqlinjection/:0:1","tags":["Security","MySQL"],"title":"SQL注入","uri":"/sqlinjection/"},{"categories":["Security"],"content":"原理 恶意拼接查询 都知道SQL语句是用;进行分隔两个语句的: SELECT*FROMusersWHEREuser_id=$user_id; 其中, user_id是传入参数, 但如果传入的参数变为1;DELETE FROM users;, 那么语句最终就会变为: SELECT*FROMusersWHEREuser_id=1;;DELETEFROMusers; 如果执行了上面的语句, 那么user表中所有数据都被删除了. 利用注释执行非法命令 SQL语句中可以添加注释: SELECT*FROMusersWHEREuser_gender='男'ANDuser_age=$age 如果user_age中包含了恶意的字符串20 OR 25 AND SLEEP(500)--, 那么语句最终会变为: SELECT*FROMusersWHEREuser_gender='男'ANDuser_age=20OR25ANDSLEEP(500)-- 上面这条语句只是想耗尽系统资源, SLEEP(500)会一直执行, 但是如果其中添加了修改, 删除数据的语句, 将会造成更大的破坏. 传入非法参数 SQL语句中的字符串是用单引号包裹的, 但是如果其本身包含单引号而没有处理, 那么就可能篡改SQL语句的作用: SELECT*FROMusersWHEREuser_name=$user_name 如果user_name传入参数值M'ustard, 那么语句最终会变为: SELECT*FROMusersWHEREuser_name='M'ustard' 一般情况下, 执行上面语句就会报错, 但是这种方式可能会产生恶意的SQL语句. 添加额外条件 在SQL语句中添加一些额外添加, 来改变执行行为. 条件一般为真值表达式: UPDATEusersSETuser_password=$user_passwordwhereuser_id=$user_id 如果user_id传入的是1 OR TRUE, 那么语句最终会变为: UPDATEusersSETuser_password='123456'whereuser_id=1ORTRUE 如果执行了上面的语句, 那么所有用户的密码都被更改了. ","date":"2022-02-24","objectID":"/sqlinjection/:0:2","tags":["Security","MySQL"],"title":"SQL注入","uri":"/sqlinjection/"},{"categories":["Security"],"content":"防御手段 过滤输入内容, 校验字符串 过滤掉用户输入中的不合法字符剔除掉, 可以使用编程语言提供的处理函数或自己封装的函数来过滤, 也可以使用正则表达式来进行匹配. 也要验证参数的类型, 比如字符串或者整型. 参数化查询 参数化查询是目前被视作预防SQL注入攻击最有效的方法. 指的设计数据库连接并访问数据时, 在需要填入数据的地方, 使用参数(Parameter)来给值. MySQL的参数格式是以?加上参数名称而成: UPDATEtable_1SETrow_1=?row_1,row_2=row_2WHERErow_3=?row_3 在使用参数化查询下, 数据库不会将参数的内容视为SQL语句的一部分来处理, 而是在数据库完成SQL语句的编译之后, 才套用参数执行. 因此就算参数中含有破坏性的指令, 也不会被数据库所运行. 安全测试, 安全审计 避免使用动态SQL 不要将敏感数据保留在纯文本中 限制数据库权限和特权 避免直接向用户显示数据库错误 ","date":"2022-02-24","objectID":"/sqlinjection/:0:3","tags":["Security","MySQL"],"title":"SQL注入","uri":"/sqlinjection/"},{"categories":["Security"],"content":"什么是CSRF攻击 CSRF攻击全称跨站请求伪造(Cross-site request forgery), 也被称为one-click attack或session riding, 通常缩写为CSRF或者XSRF. 尽管CSRF和XSS攻击很像, 但是两者的方式截然不同, 甚至可以说是相左的. XSS利用的是用户对指定网站的信任, CSRF利用的是网站对用户网页浏览器的信任. 我理解的是XSS是攻击者对浏览器下手, CSRF是对用户下手. 可以这么理解: 攻击者盗用受信任用户的身份, 以该用户的名已发送恶意请求. ","date":"2022-02-23","objectID":"/csrf/:0:1","tags":["Security","Network","HTTP"],"title":"CSRF攻击","uri":"/csrf/"},{"categories":["Security"],"content":"CSRF攻击的原理 用户1访问受信任的网站A, 输入用户名和密码登录网站A. 登录成功之后, 网站A产生Cookie信息并返回给浏览器. 用户1在未退出登录网站A的情况下, 在同一浏览器, 访问网站B. 网站B接收到请求后, 携带网站A的Cookie信息, 发出一个请求去访问网站A 网站A在接收到网站B的请求之后, 会以用户1的权限处理该请求, 从而导致用户1的隐私泄漏和财产安全受到威胁. ","date":"2022-02-23","objectID":"/csrf/:0:2","tags":["Security","Network","HTTP"],"title":"CSRF攻击","uri":"/csrf/"},{"categories":["Security"],"content":"常见的几种类型 GET类型的CSRF: 这种类型的CSRF利用非常简单, 只需要一个HTTP请求: \u003cimg src=http://xxx.com/csrf?user=xxx /\u003e 在访问这个img的页面后, 成功发出了一次HTTP请求. POST类型的CSRF: 这种类型的CSRF没有GET型的大, 利用起来通常使用的是一个自动提交的表单: \u003cform action=http://xxx.com/csrf.php method=POST\u003e \u003cinput type=\"text\" name=\"user\" value=\"xxx\" /\u003e \u003c/form\u003e \u003cscript\u003edocument.forms[0].submit();\u003c/script\u003e 其他类型CSRF: \u003cimg src=http://admin:admin@192.168.1.1 /\u003e 在访问这个img的页面后, 路由器会给用户一个合法的SESSION, 就可以进行下一步操作了. ","date":"2022-02-23","objectID":"/csrf/:0:3","tags":["Security","Network","HTTP"],"title":"CSRF攻击","uri":"/csrf/"},{"categories":["Security"],"content":"防御手段 目前防御CSRF攻击主要有三种策略: 检查HTTP Referer字段 根据HTTP协议, 在HTTP头中有一个字段叫Referer, 它记录了该HTTP请求的来源地址. 优势: 简单易行, 网站的普通开发人员不需要操心CSRF的漏洞, 只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查Referer的值就可以了. 特别是对于已有的系统来说, 不需要更改当前系统的任何代码和逻辑, 没有风险. 劣势: 这种方式是把安全性都依赖于浏览器来保障, 对于一些低版本的浏览器来说, 是可以篡改Referer值的. 对于某些最新的浏览器, 虽然不能篡改Referer的值, 但是用户有些时候会认为Referer值会记录下用户的访问来源, 所以用户自己可以设置浏览器在发送请求的时候不再提供Referer. 这种情况下, 此种方式就会认为是CSRF攻击, 从而拒绝合法用户的访问. 添加校验token CSRF之所以能够成功是因为攻击者获取到了Cookie信息. 如果能够不只是依靠Cookie中的信息来抵御CSRF攻击, 那么就可以防御了. 所以这种方式就是在HTTP请求中以参数的形式加入一个随机产生的token, 并且在服务器端建立一个拦截器来验证这个token. 优势: 这种方法比检查Referer更安全一些, token可以在用户登录之后产生并放与SESSION中, 然后每次请求时把token从SESSION中取出来进行比对. 劣势: 难以保证token本身的安全. 疑问: 可以做到每次验证token成功之后, 产生一个新的token是否可以避免此种方法可能产生的漏洞. 在HTTP头中自定义属性并验证 这种方法也是使用token进行验证, 但是不是放在参数中, 而是放在HTTP请求头的自定义属性中. 通过XMLHttpRequest这个类, 可以一次性给所有该类请求加上csrftoken这个HTTP头属性, 并把token放进去. 优势: 不会记录到浏览器的地址栏, 统一管理token输入输出, 可以保证token的安全性. 劣势: 无法在非异步的请求上实施. ","date":"2022-02-23","objectID":"/csrf/:0:4","tags":["Security","Network","HTTP"],"title":"CSRF攻击","uri":"/csrf/"},{"categories":["Security"],"content":" 昨天的时候, 部门老大提到session和OnceToken的时候, 说到了xss攻击和csrf攻击. 今天记录一下学习的内容. ","date":"2022-02-23","objectID":"/xss/:0:0","tags":["Security","Network","HTTP"],"title":"XSS(跨站脚本攻击)","uri":"/xss/"},{"categories":["Security"],"content":"什么是XSS攻击 XSS攻击全称跨站脚本攻击(Cross Site Scripting), 是一种在Web应用中的计算机安全漏洞, 它允许恶意Web用户将代码植入到提供给其他用户使用的正常页面中. 之所以缩写是XSS, 是因为如果是CSS会和层叠样式表混淆(Cascading Style Sheets). 举个简单的🌰, 恶意服务器嵌套了正常服务器中某页面的某form表单. 当用户登录了正常服务器之后, 在恶意服务器上也可以提交这个表单, 甚至拿到更高的权限. XSS是最普遍的Web应用安全漏洞. 可以做到劫持用户会话, 插入恶意内容, 重定向用户, 使用恶意软件劫持用户浏览器, 繁殖XSS蠕虫, 甚至是破坏网站, 修改路由器配置信息等. 所以XSS攻击的危害还是很严重的. ","date":"2022-02-23","objectID":"/xss/:0:1","tags":["Security","Network","HTTP"],"title":"XSS(跨站脚本攻击)","uri":"/xss/"},{"categories":["Security"],"content":"XSS原理 首先看看XSS可以插入哪里: script标签内容 HTML注释内容 HTML标签的属性名 HTML标签的属性值 HTML标签的名字 直接插入到CSS里 看到XSS可以插入到这些地方之后, 就更能理解它的原理. XSS通过一些被特殊对待的文本和标记(🌰, 小于符号\u003c 被看做是HTML标签的开始), 使得用户浏览器将这些误认为是插入了正常的内容, 所以就会在用户浏览器中被执行. 也就是说, 当这些特殊字符不能被动态页面检查或检查出现失误时, 就将会产生XSS漏洞. ","date":"2022-02-23","objectID":"/xss/:0:2","tags":["Security","Network","HTTP"],"title":"XSS(跨站脚本攻击)","uri":"/xss/"},{"categories":["Security"],"content":"分类 存储型XSS攻击(持久型): 最直接的危害类型. 将XSS代码提交存储到服务器端(数据库, 内存, 文件系统等). 这样下次请求目标页面时就不用再提交XSS代码, 会从服务器获取. 一般出现在留言, 评论, 博客日志等交互. 存储型XSS攻击 反射性XSS攻击(非持久型): 最普遍的类型. 通过特定手法(🌰email), 诱使用户访问一个包含恶意代码的地址, 当用户点击这些链接的时候, 恶意代码会在用户的浏览器执行. 一般出现在搜索栏, 用户登录口, 常用来窃取客户端Cookies或进行钓鱼欺骗. 反射型XSS攻击 DOM-based 型XSS攻击: 通过/xss修改页面的DOM(Document Object Model)结构, 是纯粹发生在客户端的攻击. 在整个攻击过程中, 服务器响应的页面没有发生变化, 取出和执行恶意代码都由浏览器端完成, 属于前端自身的安全漏洞. ","date":"2022-02-23","objectID":"/xss/:0:3","tags":["Security","Network","HTTP"],"title":"XSS(跨站脚本攻击)","uri":"/xss/"},{"categories":["Security"],"content":"防御手段 总体思路: 对用户的输入(和URL参数)进行过滤, 对输出进行编码. 也就是说, 对用户提交的所有内容进行过滤, 对URL中的参数进行过滤, 过滤掉会导致脚本执行的相关内容; 然后对动态输出到页面的内容进行html编码, 使脚本无法在浏览器中执行. 还可以服务端设置会话Cookie的HTTP Only属性, 这样客户端的JS脚本就不能获取Cookie信息了. ","date":"2022-02-23","objectID":"/xss/:0:4","tags":["Security","Network","HTTP"],"title":"XSS(跨站脚本攻击)","uri":"/xss/"},{"categories":null,"content":"Java Overview (Java Platform SE 8 ) (oracle.com) Java 8 中文版 Overview (Java SE 11 \u0026 JDK 11 ) (oracle.com) Java 11 中文版 Nacos ","date":"2022-02-22","objectID":"/documents/:1:0","tags":null,"title":"文档","uri":"/documents/"},{"categories":null,"content":"iOS Swift - Resources - Apple Developer Vapor Xcode Releases ","date":"2022-02-22","objectID":"/documents/:2:0","tags":null,"title":"文档","uri":"/documents/"},{"categories":null,"content":"Other 力扣（LeetCode）中国官网 Markdown 入门基础 | Markdown 官方教程 飞桨PaddlePaddle-源于产业实践的开源深度学习平台 Elasticsearch Guide 8.0 ","date":"2022-02-22","objectID":"/documents/:3:0","tags":null,"title":"文档","uri":"/documents/"},{"categories":["MySQL"],"content":"有了数据库之后, 还需要先进行压测 拿到一个数据库之后, 首先得先对这个数据库进行一个较为基本的基准压测. 也就是说, 你得基于一些工具模拟一个系统每秒发出1000个请求到数据库上去, 观察一下他的CPU负载、磁盘IO负载、网络 IO负载、内存复杂, 然后数据库能否每秒处理掉这1000个请求, 还是每秒只能处理500个请求? 这个过程, 就是压测. 那为什么不等到Java系统都开发完之后, 直接让Java系统连接上MySQL数据库, 然后直接对Java系统进行压测呢? 因为数据库的压测和它上面的Java系统的压测, 其实是两回事, 首先得知道数据库最大能抗多大压力, 然后再去看Java系统能抗多大压力. 因为有一种可能是, 数据库每秒可以抗下2000个请求, 但是Java系统每秒只能抗下500个请求. 所以不能光是对Java系统去进行压测, 在那之前也得先对数据库进行压测, 做到心里有个数. ","date":"2022-01-10","objectID":"/mysql_4/:1:0","tags":["Database","MySQL"],"title":"MySQL压力测试","uri":"/mysql_4/"},{"categories":["MySQL"],"content":"QPS和TPS到底有什么区别 既然是要压测, 那么肯定得先明白一点, 每秒能抗下多少个请求, 其实是有专业术语的, 分别是QPS和TPS. QPS: Query Per Second. 也就是说数据库每秒可以处理多少个请求, 大致可以理解为一次请求就是一条SQL语句, 也就是说数据库可以每秒处理多少个SQL语句. Java系统或者中间件系统在进行压测的时候, 也可以使用这个指标. TPS: Transaction Per Second. 指的是每秒可以处理的事务量. 就是说数据库可以每秒处理多少次事务提交或者回滚. ","date":"2022-01-10","objectID":"/mysql_4/:2:0","tags":["Database","MySQL"],"title":"MySQL压力测试","uri":"/mysql_4/"},{"categories":["MySQL"],"content":"IO相关的压测性能指标 IOPS: 指的是机器的随机IO并发处理能力. 举个🌰: 机器可以达到200 IOPS, 意思就是说每秒可以执行200个随机IO读写请求. 这个指标很关键, 因为在之前说过, 在内存中更新的脏数据库, 最后都由后台IO线程在不确定的时间, 刷回到磁盘中去, 这就是随机IO的过程. 也就是说, 如果IOPS指标太低, 那么就会导致内存里的脏数据库刷回磁盘的效率不高. 吞吐量: 指的是机器的磁盘存储每秒可以读写多少字节的数据量. 这个指标也很关键, 之前也说过, 在执行各种SQL语句的时候, 提交事务的时候, 其实都是大量的会写redo log之类的日志的, 这些日志都会直接写磁盘文件. 所以一台机器的存储每秒可以读写多少字节的数据量, 就决定了他每秒可以把多少redo log之类的日志写入到磁盘里去. 一般来说, 我们写redo log之类的日志, 都是对磁盘文件进行顺序写入的, 也就是一行接着一行的写, 不会说进行随机的读写, 那么一般普通磁盘的顺序写入的吞吐量每秒都可以达到200MB左右. 所以通常而言, 机器的磁盘吞吐量都是足够承载高并发请求的. latency: 指的是往磁盘里写入一条数据的延迟. 这个指标同样重要, 因为执行SQL语句的和提交事务的时候, 都需要顺序写redo log磁盘文件, 所以此时写一条日志到磁盘文件里去, 到底是延迟1ms, 还是延迟100us, 这就对数据库的SQL语句执行性能是有影响的. ","date":"2022-01-10","objectID":"/mysql_4/:3:0","tags":["Database","MySQL"],"title":"MySQL压力测试","uri":"/mysql_4/"},{"categories":["MySQL"],"content":"压测的时候要关注的其他性能指标 CPU负载: 这个也是一个很重要的指标. 因为假设数据库压测到了3000 QPS, 可能其他指标都还正常, 但是此时CPU负载特别高, 那么也说明你的数据库不能继续往下压测更高的QPS了, 否则CPU是吃不消的. 网络负载: 这个就是看机器带宽情况下, 在压测到一定的QPS和TPS的时候, 每秒钟机器的网卡会输入多少MB数据, 会输出多少MB数据. 因为有可能网络带宽最多每秒传输100MB的数据, 那么可能QPS到1000的时候, 网卡就打满了, 已经每秒传输100MB的数据了, 此时即使其他指标还正常, 也不能继续压测下去了. 内存负载: 这个就是看压测到一定情况下的时候, 机器内存损耗了多少, 如果说机器内存损耗过高了, 说明也不能继续压测下去了. ","date":"2022-01-10","objectID":"/mysql_4/:4:0","tags":["Database","MySQL"],"title":"MySQL压力测试","uri":"/mysql_4/"},{"categories":["MySQL"],"content":"推荐压测工具 sysbench, 这个工具可以自动帮你在数据库里构建出来大量的数据. 然后也可以模拟几千个线程并发的访问数据库, 模拟各种sql语句, 包括各种书屋提交到数据库里, 甚至可以模拟出几十万的TPS对数据库进行压测. ","date":"2022-01-10","objectID":"/mysql_4/:5:0","tags":["Database","MySQL"],"title":"MySQL压力测试","uri":"/mysql_4/"},{"categories":["MySQL"],"content":"生产数据库一般用什么配置的机器 首先要明确的一点, 如果系统是一个没什么并发访问量, 用户就几十个人或者几百个人的系统, 那么其实选择什么样的机器去部署数据库, 影响不大. 哪怕是个人笔记本电脑去部署一个MySQL数据库, 其实也能支撑地并发系统的运行. 因为这种系统可能每个几分钟才会有一波请求发到数据库上, 而且数据库里一张表也许就几百条, 几千条或者是几万条. 数据量很小, 并发量很小, 操作频率很低, 用户量很小, 并发量很小, 只不过可能系统的业务逻辑很复杂而已. 对于这类系统的数据库机器选型, 什么样都可以. ","date":"2021-12-27","objectID":"/mysql_3/:1:0","tags":["Database","MySQL"],"title":"MySQL生产经验","uri":"/mysql_3/"},{"categories":["MySQL"],"content":"普通的Java应用系统部署在机器上能抗多少并发 通常来说, Java应用系统部署的时候常选用的机器配置大致是2核4G和4核8G的较多一些, 数据库部署的时候常选用的机器配置最低在8核16G以上, 正常在16核32G. 那么以大量的高并发线上系统的生产经验观察下来而言, 一般Java应用系统部署在4核8G的机器上, 每秒钟抗下500左右的并发访问量, 差不多是比较合适的. 当然这个也不是绝对的, 假设每个请求花费1s可以处理完, 那么一台机器每秒也许只可以处理100个请求, 但是如果每个请求只要花费100ms就可以处理完, 那么一台机器每秒也许就可以处理几百个请求. 所以一台机器能抗下每秒多少请求, 往往是跟每个请求处理耗费多长时间关联的. 但是大体上来说, 根据大量的经验观察而言, 4核8G的机器部署普通的Java应用系统, 每秒大致能抗下几百的并发访问, 从每秒一两百请求到每秒七八百请求, 都是有可能的, 关键是每个请求耗费多长时间. ","date":"2021-12-27","objectID":"/mysql_3/:2:0","tags":["Database","MySQL"],"title":"MySQL生产经验","uri":"/mysql_3/"},{"categories":["MySQL"],"content":"高并发场景下, 数据库应该用什么样的机器 对于数据库而言, 上文也说了, 通常推荐的数据至少是选用8核16G以上的机器更加合适. 因为要考虑一个问题, 对于我们的Java应用系统, 主要耗费时间的是Java系统和数据库之间的网络通信. 对Java系统自己而言, 如果仅仅只是系统内部运行一些普通的业务逻辑, 纯粹在自己内存中完成一些业务逻辑, 这个性能是极高极高的. 对于Java系统受到的每个请求, 耗时最多的还是发送网络请求到数据库上去, 等待数据库执行一些SQL语句, 返回结果给Java系统. 所以其实常说的Java系统压力很大, 负载很高. 其实主要的压力和复杂都是集中在依赖的那个MySQL数据库上! 因为执行大量的增删改查的SQL语句的时候, MySQL数据库需要对内存和磁盘文件进行大量的IO操作, 所以数据库往往是负载最高的! 通过经验而言, 一般8核16G的机器部署的MySQL数据库, 每秒抗个一两千并发请求是没问题的, 但是如果并发量再高一些, 假设每秒有几千并发请求, 那么可能数据库就会有危险了, 因为数据库的CPU、磁盘、IO、内存的负载都会很高, 弄不好数据库压力过大就会宕机. 对于16核32G的机器部署的MySQL数据库而言, 每秒两三千, 甚至三四千的并发也都是可以的, 但是如果达到每秒上万请求, 也是会有宕机的危险. 如果可以的话, 数据库机器周最好用SSD的硬盘而不是机械硬盘. ","date":"2021-12-27","objectID":"/mysql_3/:3:0","tags":["Database","MySQL"],"title":"MySQL生产经验","uri":"/mysql_3/"},{"categories":["MySQL"],"content":"申请机器机器之后做好心中有数, 交给专业的DBA部署 数据库机器申请下来之后, 作为架构师要对机器做到心中有数. 比如申请的是8核16G的机器, 心里大致就该知道这个数据库每秒抗个一两千请求是可以的, 如果申请的是16核32G的机器, 那心里知道妥妥可以抗个每秒两三千, 甚至三四千的请求. 其次, 申请一台机器下来之后, 接着这台机器在有一定规模的公司里, 一定是交给公司专业的DBA去安装、部署和启动MySQL的. DBA这个时候会按照他国王的经验, 用自己的MySQL生产调优参数模板, 直接放到MySQL里去, 然后用一个参数模板去启动这个MySQL, 往往这里很多参数都是调优过的. 而且DBA还可能对linux机器一些OS内核参数进行一定的调整, 比如说最大文件句柄之类的参数, 这些参数往往也都是需要调整的. ","date":"2021-12-27","objectID":"/mysql_3/:4:0","tags":["Database","MySQL"],"title":"MySQL生产经验","uri":"/mysql_3/"},{"categories":["MySQL"],"content":"什么是InnoDB? InnoDB是第一个提供外键约束的存储引擎, 而且它对事务的处理能力是其它存储引擎无法与之比拟的. MySQL在5.5版本之后, 默认存储引擎由MyISAM修改为InnoDB. 目前, InnoDB是最重要的, 也是使用最广泛的存储引擎. 1. InnoDB优势: 支持事务安装 灾难恢复性好 使用行级锁 实现了缓冲处理 支持外键 适合需要大型数据库的网站 2. 物理存储 数据文件(表数据和索引数据): 共享表空间 独立表空间 日志文件 ","date":"2021-12-23","objectID":"/mysql_2/:1:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"更新语句在MySQL中是如何执行的? 首先假设有一条语句是这样的: UPDATEusersSETname='xxx'WHEREid=10 这条语句是如何执行的呢? 首先肯定是系统通过一个数据库连接发送到了MySQL上, 然后经过SQL接口、解析器、优化器、执行器几个环节, 解析SQL语句, 生成执行计划, 接着由执行器负责这个计划的执行, 调用InnoDB存储引擎的接口去执行. ","date":"2021-12-23","objectID":"/mysql_2/:2:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"InnoDB的重要内存结构: 缓冲池 前面提到了InnoDB的一个优势就是\"实现了缓冲处理\", 就是通过InnoDB存储引擎中的一个非常重要的放在内存里的组件实现的, 就是缓冲池(Buffer Pool). 这个里面会存很多数据, 便于以后的查询, 要是缓冲池里有数据, 就不会去磁盘查询. 所以当执行上面那条更新语句的时候, 就会现将id=10这一行数据看看是否在缓冲池里, 如果不在的话, 那么会直接从磁盘里加载到缓冲池里来, 而且还会对这行记录加锁. ","date":"2021-12-23","objectID":"/mysql_2/:3:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"undo日志文件: 如何让你更新的数据可以回滚 接着下一步, 假设id=10这行数据的name原来是\"zhangsan\", 现在我们更新为\"xxx\", 那么此时得现将要更新的原来的值\"zhangsan\"和id=10这些信息, 写入到undo日志文件中去. 其实大家都知道, 如果执行一个更新语句是在一个事务里的话, 那么事务提交之前我们都是可以对数据进行**回滚(rollback)**的. ","date":"2021-12-23","objectID":"/mysql_2/:4:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"更新buffer pool中的缓存数据 当我们把要更新的那行记录从磁盘文件加载到缓冲池, 也对其进行加锁之后, 并且还把更新前的旧值写入undo日志文件之后, 就可以正式开始更新这行记录了. 更新的时候, 先是会更新缓冲池中的记录, 此时这个数据就是脏数据了. 为什么是脏数据: 因为此时的磁盘中id=10这行数据的name还是\"zhangsan\", 还不是\"xxx\". ","date":"2021-12-23","objectID":"/mysql_2/:5:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"Redo Log Buffer: 万一系统宕机, 如何避免数据丢失 如果按照上面的操作进行更新, 现在已经把内存里的数据进行了修改, 但是磁盘上的数据还没有修改. 就在这个时候, 系统宕机了, 该怎么办? 这个时候就必须要把对内存所做的修改写入到一个Redo Log Buffer里去, 这也是一个内存的缓冲区, 用来存放redo日志的. redo日志用来记录对什么记录进行了修改, 比如对id=10这行记录修改了name为\"xxx\", 这就是一个日志. 这个redo日志其实就是用来在MySQL突然宕机的时候, 用来恢复更新过的数据的. ","date":"2021-12-23","objectID":"/mysql_2/:6:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"如果还没提交事务, MySQL宕机了怎么办 如果还没有提交事务, 那么此时如果MySQL崩溃, 必然导致内存里Buffer Pool中的修改过的数据都丢失, 同时写入Redo Log Buffer中的redo日志也会消失. 其实此时数据丢失是不要紧的, 因为一个更新语句, 没提交事务, 就代表还没有执行成功, 此时MySQL宕机虽然导致内存里的数据都丢失了, 但是会发现, 磁盘上的数据怡然居还停留在原样子. 换句话说, id=10那行数据的name字段的值还是旧值\"zhangsan\", 所以此时这个事务就是执行失败了, 没能成功完成更新, 会收到一个数据库的异常. 然后当MySQL重启之后, 数据并没有任何变化. 所以, 如果还没提交事务时, MySQL宕机了, 不会有任何问题. ","date":"2021-12-23","objectID":"/mysql_2/:7:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"提交事务的时候将redo日志写入磁盘中 接着俩要提交一个事务了, 此时就会根据一定的策略把redo日志从redo log buffer里刷入到磁盘文件里去. 这个策略是通过innodb_flush_log_at_trx_commit来配置的, 它有几个选项. 当这个参数的值为0的时候, 那么当提交事务的时候, 不会把redo log buffer里的数据刷入磁盘文件, 此时可能都提交事务了, 结果MySQL宕机了, 然后内存里的数据全部丢失了. 这就相当于提交事务成功了, 但是由于MySQL宕机, 导致内存中的数据和redo日志都丢失了. 当这个参数的值为1的时候, 那么当提交事务的时候, 就必须把redo log buffer从内存刷入到磁盘文件里去, 只有事务提交成功, 那么redo log就必然在磁盘里了. 所以只有提交事务成功之后, redo日志一定在磁盘文件里. 也就是说, 哪怕此时buffer pool中更新过的数据还没刷新到磁盘里去, 此时内存里的数据已经是更新过name=\"xxx\", 然后磁盘上的数据还是没更新过的name=\"zhangsan\". 当MySQL重启之后, 可以根据redo日志去恢复之前做过的修改. 当这个参数的值是2的时候, 那么当提交事务的时候, 把redo日志写入磁盘文件对应的os cache里去, 而不是直接进入磁盘文件, 可能1秒之后才会吧os cache里的数据写入到磁盘文件里去. 这种模式下, 提交事务之后, redo log可能仅仅停留在os cache内存缓存里, 没实际进入磁盘文件, 玩意此时要是机器宕机了, 那么os cache里的redo log就会丢失, 同样会感觉提交事务了, 但是结果数据丢了. ","date":"2021-12-23","objectID":"/mysql_2/:8:0","tags":["Database","MySQL"],"title":"InnoDB存储引擎的架构设计","uri":"/mysql_2/"},{"categories":["MySQL"],"content":"什么是CRUD? CRUD是指在做计算处理时的增加(Create), 读取查询(Retrieve), 更新(Update)和删除(Delete). 主要是被用在描述软件系统中DataBase或者持久层的基本操作. ","date":"2021-12-13","objectID":"/mysql_1/:1:0","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"什么是数据库驱动? 想要访问数据库, 就需要和数据库建立一个网络连接. 那么, 建立这个网络连接的就是数据库驱动. 所以对于MySQL来说, 对应每种常见的编程语言(e.g. Java, PHP, .NET, Python, Ruby等), MySQL都会提供对应语言的MySQL驱动. 其实数据库驱动就是中间件. ","date":"2021-12-13","objectID":"/mysql_1/:2:0","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"数据库连接池是用来干嘛的? 首先要知道的是, 一个系统和数据库建立的连接往往都不止一个. 但是每次访问数据库的时候都建立一个连接, 然后执行SQL语句, 然后再销毁这个连接, 这种方式显然是不合适的. 因为每次建立一个数据库连接都很耗时, 效率会很低下. 所以, 就出现了数据库连接池这个东西. 一个数据库连接池里会维持多个连接, 让多个线程使用里面的不同的数据库连接去执行SQL语句, 执行完语句之后, 不是销毁这个连接, 而是把它放回池子里, 后面还能继续用. 常见的数据库连接池有DBCP, C3P0, Druid ","date":"2021-12-13","objectID":"/mysql_1/:3:0","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"MySQL是如何执行一条SQL语句的? ","date":"2021-12-13","objectID":"/mysql_1/:4:0","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"第一步 线程: 接收SQL语句 首先, 假设数据库服务器的连接池中的某个连接收到了网络请求, 假设就是一条SQL语句, 这个工作一定是一个线程来进行处理的, 来监听请求以及读取请求数据. 当MySQL的工作线程接收到SQL语句之后, 会转交给SQL接口去执行. SQL接口(SQL Interface)就是MySQL内部提供的一个组件, 是一套执行SQL语句的接口. ","date":"2021-12-13","objectID":"/mysql_1/:4:1","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"第二步 SQL接口: 解析SQL语句 那么, SQL接口又是如何执行SQL语句的呢? 比如要执行下面这条语句: SELECTid,name,ageFROMusersWHEREid=1; MySQL本身也是一个系统, 是一个数据库管理系统(DBMS), 是没法直接理解这些语句的, 所以就需要**查询解析器(Parser)**出场了! 这个查询解析器是负责对SQL语句进行解析的, 比如上面的语句拆解一下, 可以拆解为一下几个部分: 我们现在要从users表里查询数据 查询id字段的值等于1的那行数据 对查出来的哪行数据要提取里面的id, name, age三个字段 所谓的SQL解析, 就是按照既定的SQL语法, 对我们按照SQL语法规则编写的SQL语句进行解析, 然后理解这个SQL语句要干什么事情. ","date":"2021-12-13","objectID":"/mysql_1/:4:2","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"第三步 查询优化器: 选择最优查询路径 当通过解析器理解了SQL语句要干什么之后, 接着就会找**查询优化器(Optimizer)**来选择一个最优的查询路径. ","date":"2021-12-13","objectID":"/mysql_1/:4:3","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"第四步 存储引擎: 调用存储引擎接口, 真正执行SQL语句 最后一步, 就是把查询优化器选择的最有查询路径交给底层的存储引擎去真正的执行. 存储引擎是MySQL架构设计中很有特色的一个环节. 在真正执行SQL语句的时候, 要不是更新数据, 要不是查询数据, 但是具体的数据是存放在内存里还是在磁盘里呢? 这个时候就需要存储引擎了, 存储引擎其实就是执行SQL语句的, 它是按照一定的步骤去查询内存缓存数据, 更新磁盘数据, 查询磁盘数据等等, 执行诸如此类的一系列的操作. MySQL的架构设计中, SQL接口, SQL解析器, 查询优化器其实都是通用的, 就是一套组件而已. 但是是支持各种各样的存储引擎的, 比如常见的InnoDB, MyISAM, Memory等等, 我们是可以选择使用哪种存储引擎来负责具体的SQL语句执行的. ","date":"2021-12-13","objectID":"/mysql_1/:4:4","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":["MySQL"],"content":"第五步 执行器: 根据执行计划调用存储引擎的接口 现在回过头来看一个问题, 存储引擎可以访问内存和磁盘上的数据, 那么是谁来调用存储引擎的接口呢? 其实还漏了一个执行器的概念, 执行器会根据优化器选择的执行方案, 去调用存储引擎的接口按照一定的顺序和步骤, 就把SQL语句的逻辑给执行了. 举个🌰: 比如执行器可能会先调用存储引擎的一个接口, 去获取users表中的第一行数据, 然后判断一下这个数据的id字段的值是否等于我们期望的值, 如果不是的话, 就继续调用存储引擎的接口, 去获取users表的下一行数据. 基于上述的思路, 执行器就会去根据优化器生成的一套执行计划, 然后不停的调用存储引擎的各种接口去完成SQL语句的执行计划, 大致就是不听的更新或者提取一些数据出来. ","date":"2021-12-13","objectID":"/mysql_1/:4:5","tags":["Database","MySQL"],"title":"MySQL总览","uri":"/mysql_1/"},{"categories":null,"content":"初衷 Since: 2021-11-20 08:27:00 ","date":"2021-11-20","objectID":"/about/:1:0","tags":null,"title":"关于 Buli Home","uri":"/about/"},{"categories":null,"content":"期许 不卑不亢，不矜不伐，戒骄戒躁 不嗔不怒，不争不弃，独善其身 ","date":"2021-11-20","objectID":"/about/:2:0","tags":null,"title":"关于 Buli Home","uri":"/about/"},{"categories":null,"content":"About me 在职: iOS开发程序猿, Java开发程序猿 用我所学, 学我所用. 不盲目堆叠技术栈, 保持谦逊, 保持探索欲, 砥砺前行. ","date":"2021-11-20","objectID":"/about/:3:0","tags":null,"title":"关于 Buli Home","uri":"/about/"},{"categories":null,"content":"Other Annual Summary /years/ ","date":"2021-11-20","objectID":"/about/:4:0","tags":null,"title":"关于 Buli Home","uri":"/about/"}]